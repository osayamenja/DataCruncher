{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Aristos\n",
    "This notebook includes the raw traces, data and code for generating the figures in the featured paper.\n",
    "\n",
    "We preserve the figure labels from the paper and delineate each code cell accordingly. Each cell contains the following:\n",
    "- Documentation\n",
    "- Dataset and code for a specific figure\n",
    "\n",
    "We start with necessary imports. Ensure to install missing packages via `pip`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1eee63706611d7d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:20.038591Z",
     "start_time": "2024-03-09T02:59:18.065440Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bisect\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading\n",
    "For a collective operation, below returns the min and max durations across concurrent executions on `num_gpus`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3bb904831d87506"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_collective_duration(data_file: str,\n",
    "                            delimiter_regex: str,\n",
    "                            gpus_per_node: int,\n",
    "                            duration_index: int,\n",
    "                            skip=1,\n",
    "                            time_unit='ms') -> [list, list, float]:\n",
    "    scaling_factor = 1  # us\n",
    "    if time_unit == 'ms':\n",
    "        scaling_factor = 1000\n",
    "    elif time_unit == 's':\n",
    "        scaling_factor = 1000 * 1000\n",
    "\n",
    "    durations = open(data_file, \"r\")\n",
    "    total_durations = []\n",
    "    actual_durations = []\n",
    "    max_delay = 0.0  # >= 0\n",
    "    max_delay_index = 0\n",
    "    p = re.compile(delimiter_regex)\n",
    "    for _ in range(skip):\n",
    "        durations.readline()  # skip header information\n",
    "\n",
    "    line = durations.readline()\n",
    "\n",
    "    j = 0\n",
    "    while line:\n",
    "        split_line = p.findall(line)\n",
    "        duration = (float(split_line[duration_index - 1]) / scaling_factor)\n",
    "        total = duration\n",
    "        actual = duration\n",
    "\n",
    "        line = durations.readline()\n",
    "\n",
    "        for i in range(1, gpus_per_node):  # Obtain longest and shortest duration from concurrent executions\n",
    "            split_line = p.findall(line)\n",
    "            duration = (float(split_line[duration_index - 1]) / scaling_factor)  # microseconds to milliseconds\n",
    "            total = max(duration, total)\n",
    "            actual = min(actual, duration)\n",
    "            line = durations.readline()\n",
    "\n",
    "        if (total - actual) > max_delay:\n",
    "            max_delay_index = j\n",
    "            max_delay = (total - actual)\n",
    "        total_durations.append(total)\n",
    "        actual_durations.append(actual)\n",
    "        j = j + 1\n",
    "    return total_durations, actual_durations, max_delay_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:21.331294Z",
     "start_time": "2024-03-09T02:59:21.327174Z"
    }
   },
   "id": "79241f9344a44dc9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def single_plot(data_x: np.ndarray, data: list, header: str, x_title: str, out_name: str,\n",
    "                color=None, y_title=None, labels=None, n_plots=None, stats=None, s_coords=None,\n",
    "                x_lim_left=None, x_lim_right=None, y_lim_top=None, y_lim_bottom=None,\n",
    "                plot_marker=None, sub_title=None):\n",
    "    fig, axs = pyplot.subplots(figsize=(6, 5), dpi=300)\n",
    "    fig.suptitle(header, fontsize=10)\n",
    "    if n_plots == 1:\n",
    "        axs.plot(data_x, data, color)\n",
    "    else:\n",
    "        for i in range(n_plots):\n",
    "            axs.plot(data_x, data[i], color[i], label=labels[i], marker=plot_marker)\n",
    "    if stats is not None:\n",
    "        bbox = dict(boxstyle='round', fc='blanchedalmond', ec='orange', alpha=0.5)\n",
    "        axs.text(s_coords[0], s_coords[1], stats, fontsize=8, bbox=bbox,\n",
    "                 transform=axs.transAxes, horizontalalignment='right')\n",
    "    axs.set_xlabel(x_title)\n",
    "\n",
    "    if y_title != \"\":\n",
    "        axs.set_ylabel(y_title)\n",
    "\n",
    "    if sub_title is not None:\n",
    "        axs.set_title(sub_title, fontsize=8)\n",
    "\n",
    "    if x_lim_left is not None:\n",
    "        axs.set_xlim(left=x_lim_left, right=x_lim_right)\n",
    "\n",
    "    if y_lim_top is not None:\n",
    "        axs.set_ylim(top=y_lim_top, bottom=y_lim_bottom)\n",
    "\n",
    "    if labels is not None:\n",
    "        axs.legend()\n",
    "    axs.grid()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    pyplot.savefig(out_name)\n",
    "    pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:22.052022Z",
     "start_time": "2024-03-09T02:59:22.047714Z"
    }
   },
   "id": "3c1c9b81adf19c5c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_kernel_percentages(data_file: str, delimiter_regex: str, metadata: dict, skip=0) -> tuple[list, list]:\n",
    "    percentages = []\n",
    "    for _ in range(len(metadata)):\n",
    "        percentages.append(0.0)\n",
    "\n",
    "    summary = open(data_file, \"r\")\n",
    "    p = re.compile(delimiter_regex)\n",
    "\n",
    "    for _ in range(skip):\n",
    "        summary.readline()\n",
    "\n",
    "    line = summary.readline()\n",
    "    non_misc_percentages = 0\n",
    "    while line:\n",
    "        split_summary = p.findall(line)\n",
    "        time_percent = float(split_summary[0])\n",
    "\n",
    "        if time_percent > 0.0:\n",
    "            for i in range(10, len(split_summary)):\n",
    "                stop_search = False\n",
    "                j = 0\n",
    "                # This is correct since dict remembers insertion order per https://stackoverflow.com/a/39980744\n",
    "                for kernel_pattern in metadata.keys():\n",
    "                    val = split_summary[i]\n",
    "                    if re.match(kernel_pattern, val):\n",
    "                        percentages[j] = percentages[j] + time_percent\n",
    "                        non_misc_percentages = non_misc_percentages + time_percent\n",
    "                        stop_search = True\n",
    "                        break\n",
    "                    j = j + 1\n",
    "                if stop_search:\n",
    "                    print(line)\n",
    "                    break\n",
    "\n",
    "        line = summary.readline()\n",
    "\n",
    "    kernel_groups = list(metadata.values())\n",
    "    kernel_groups.append(\"Misc\")\n",
    "    percentages.append(100.0 - non_misc_percentages)\n",
    "\n",
    "    return kernel_groups, percentages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:22.713099Z",
     "start_time": "2024-03-09T02:59:22.709251Z"
    }
   },
   "id": "3a32b30357c7adb9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_kernel_breakdown(data_file: str, delimiter_regex: str, cutoff: float, skip=0, misc_index=-1) -> list:\n",
    "    percentages = []\n",
    "\n",
    "    summary = open(data_file, \"r\")\n",
    "    p = re.compile(delimiter_regex)\n",
    "\n",
    "    for _ in range(skip):\n",
    "        summary.readline()\n",
    "\n",
    "    line = summary.readline()\n",
    "    non_misc_percentages = 0\n",
    "    \n",
    "    split_summary = p.findall(line)\n",
    "    time_percent = float(split_summary[0])\n",
    "    \n",
    "    while time_percent >= cutoff:\n",
    "        non_misc_percentages = non_misc_percentages + time_percent\n",
    "        percentages.append(time_percent)\n",
    "        \n",
    "        line = summary.readline()\n",
    "        split_summary = p.findall(line)\n",
    "        time_percent = float(split_summary[0])\n",
    "    \n",
    "    percentages.insert(misc_index, 100.0 - non_misc_percentages)\n",
    "    \n",
    "    return percentages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:23.265439Z",
     "start_time": "2024-03-09T02:59:23.262584Z"
    }
   },
   "id": "7a99c9c776369031",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adapted from https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_and_donut_labels.html\n",
    "def plot_donut_chart(description: list, data: list, title: str, out_name:str, y_size=3) -> None:\n",
    "    fig, ax = pyplot.subplots(figsize=(6, y_size), subplot_kw=dict(aspect=\"equal\"), dpi=300)\n",
    "\n",
    "    wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n",
    "\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    kw = dict(arrowprops=dict(arrowstyle=\"->\"),\n",
    "              bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "    for i, p in enumerate(wedges):\n",
    "        ang = (p.theta2 - p.theta1) / 2. + p.theta1\n",
    "        y = np.sin(np.deg2rad(ang))\n",
    "        x = np.cos(np.deg2rad(ang))\n",
    "        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "        connectionstyle = f\"angle,angleA=0,angleB={ang}\"\n",
    "        kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "        ax.annotate('{}: {:.1f}%'.format(description[i], data[i]), xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),\n",
    "                    horizontalalignment=horizontalalignment, **kw)\n",
    "\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    pyplot.savefig(out_name, format= 'pdf', bbox_inches='tight')\n",
    "    pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:23.790586Z",
     "start_time": "2024-03-09T02:59:23.786629Z"
    }
   },
   "id": "f1b8a5107d4f006c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def gen_batch_collective_duration(data_files: list,\n",
    "                                  delimiter_regex: str,\n",
    "                                  gpus_per_node: list,\n",
    "                                  duration_index: int,\n",
    "                                  skips=None,\n",
    "                                  time_unit='ms') -> list:\n",
    "    if skips is None:\n",
    "        skips = [0, 0, 0]\n",
    "    batch = []\n",
    "    for filename, n_gpus, skip in zip(data_files, gpus_per_node, skips):\n",
    "        t_dur, a_dur, max_i = get_collective_duration(data_file=filename,\n",
    "                                                      delimiter_regex=delimiter_regex,\n",
    "                                                      gpus_per_node=n_gpus,\n",
    "                                                      duration_index=duration_index,\n",
    "                                                      skip=skip,\n",
    "                                                      time_unit=time_unit)\n",
    "        batch.append((t_dur, a_dur, max_i))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def plot_straggler_delays(dataset: list, output_names: list, file_prefix=\"\", addenda=None, \n",
    "                          x_left=None, x_right=None) -> None:\n",
    "    if addenda is None:\n",
    "        addenda = []\n",
    "        for _ in range(len(dataset)):\n",
    "            addenda.append(\"\")\n",
    "\n",
    "    plot_stats = []\n",
    "    coord = [(0.7, 0.8), (0.7, 0.9), (0.7, 0.65)]\n",
    "    dur_unit = 'ms'\n",
    "\n",
    "    for row in dataset:\n",
    "        m_idx = row[2]\n",
    "        plot_stats.append((f'max delay = {(row[0][m_idx] - row[1][m_idx]): .2f} ' + dur_unit + \n",
    "                           f'\\n avg actual = {np.array(row[1]).mean(): .2f}' + dur_unit))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        output_name = \"{}{}.pdf\".format(file_prefix, re.sub(r'\\s+', \"_\", output_names[i]))\n",
    "        data_x = np.linspace(1, len(dataset[i][0]), num=len(dataset[i][0]), dtype=int)\n",
    "\n",
    "        single_plot(data_x, [dataset[i][0], dataset[i][1]],\n",
    "                    header=\"{} All-to-All Straggler Effect: {}\".format(output_names[i], addenda[i]),\n",
    "                    labels=[\"Total Time\", \"Actual Time\"], stats=plot_stats[i], s_coords=coord[i], color=['tab:red', 'tab:green'],\n",
    "                    out_name=output_name, y_title=\"Time ({})\".format(dur_unit),\n",
    "                    x_title=\"All-to-All Steps\", n_plots=2, sub_title=\"Raw Distribution\", x_lim_left=x_left, x_lim_right=x_right)\n",
    "\n",
    "\n",
    "def plot_ecdf(dataset: list, output_names: list, file_prefix=\"\", addenda=None) -> None:\n",
    "    for i in range(len(dataset)):\n",
    "        t_durs = np.array(dataset[i][0])\n",
    "        a_durs = np.array(dataset[i][1])\n",
    "        ecdf = ECDF((t_durs - a_durs))\n",
    "        median_cdf = bisect.bisect(ecdf.y, 0.5)\n",
    "        x_unit = 'ms'\n",
    "        filtered_data = [v for v in ecdf.x if not math.isnan(v) and not math.isinf(v)]\n",
    "        \n",
    "        stats = (f'$\\mu$ = {np.array(filtered_data).mean():.2f}{x_unit}\\n'\n",
    "             f'$median$ = {ecdf.x[median_cdf]:.2f}{x_unit}')\n",
    "        \n",
    "        output_name = \"{}{}_ecdf.pdf\".format(file_prefix, re.sub(r'\\s+', \"_\", output_names[i]))\n",
    "        single_plot(ecdf.x, ecdf.y,\n",
    "                    header=\"{} All-to-All Straggler Effect ECDF: {}\".format(output_names[i], addenda[i]),\n",
    "                    color='tab:green', out_name=output_name, x_title=\"Delay ({})\".format(x_unit), n_plots=1, sub_title=\"ECDF\", stats=stats, s_coords=(0.7, 0.8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:24.422065Z",
     "start_time": "2024-03-09T02:59:24.415377Z"
    }
   },
   "id": "c27346463dc06d01",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "values = get_kernel_breakdown(\"data/single/single_1x8_filtered_sum.txt\", r\"(\\d+\\.?\\d+|[^\\W_]+)\", cutoff=6, skip=6, misc_index=0)\n",
    "print(values)\n",
    "# Manually obtained below from ./data/single_1x8_filtered_sum.txt\n",
    "kernel_types = [\"miscellaneous\", \"volta_128x128_s884\", \"apex_fused_dropout\", \"cutlass_fused_relu_256\", \"volta_s884_64x128_tn\", \"volta_s884_64x128_nn\", \"nccl_All-to-All\", \"cutlass_fused_relu_128\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d42526b1cf4f60a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Communication Overhead: Figure 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "307c1966917e63ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_donut_chart(kernel_types, values, \"GPT-3 MoE 8x350M Training Step CUDA Kernel Summary: 1x8 V100 GPUs\", \"figures/single_trace_1x8_donut.pdf\", y_size=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2856aea31a152072",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m_values = get_kernel_breakdown(\"data/multi/multi_8x4_1.3B_sum.txt\", r\"(\\d+\\.?\\d+|[^\\W_]+)\", cutoff=5, skip=6, misc_index=0)\n",
    "print(m_values)\n",
    "\n",
    "m_kernel_types = [\"miscellaneous\", \"nccl_All-to-All\", \"ampere_s16816_128x128_tn\", \"ampere_s16816_256x128\", \"ampere_s16816_128x128_nt\", \"ampere_s16816_128x256_tn\", \"ampere_s1688_256x128_tn\", \"apex_fused_dropout\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a702d615a51c984e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_donut_chart(m_kernel_types, m_values, \"GPT-3 MoE 32x1.3B Training Step CUDA Kernel Summary: 8x4 A100 GPUs\", \"figures/multi_sum_8x4_1.3B_donut.pdf\", y_size=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e9d2e5c01a9841a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m_t_values = get_kernel_breakdown(\"data/multi/multi_8x4_350M_sum.txt\", r\"(\\d+\\.?\\d+|[^\\W_]+)\", cutoff=4, skip=6, misc_index=0)\n",
    "print(m_t_values)\n",
    "\n",
    "m_t_kernel_types = [\"miscellaneous\", \"nccl_All-to-All\", \"apex_fused_dropout\", \"ampere_s1688gemm_256x64_tn\",\"tensor_scan_outer_dim\", \"ampere_s16816gemm_128x128_nt\", \"apex_softmax\", \"ampere_s16816gemm_128x128_nn\", \"ampere_s16816gemm_64x128_nn\", \"cutlass_fused_relu_256x128_tn\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82bc30e1e3965ca6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_donut_chart(m_t_kernel_types, m_t_values, \"GPT-3 MoE 32x350M Training Step CUDA Kernel Summary: 8x4 A100 GPUs\", \"figures/multi_sum_8x4_350M_donut.pdf\", y_size=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31bcff21764831ed",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Straggler Effect: Figure 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de90f223e43844f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "delim = r\"(\\d+\\.?\\d+)\"\n",
    "delays_dataset = gen_batch_collective_duration(data_files=[\"data/single/single_1x8_350M_trace.txt\",\n",
    "                                                           \"data/multi/multi_8x4_1.3B_trace.txt\",\n",
    "                                                           \"data/multi/multi_8x4_350M_trace.txt\"],\n",
    "                                               delimiter_regex=delim,\n",
    "                                               gpus_per_node=[8, 4, 4],\n",
    "                                               duration_index=2,\n",
    "                                               skips=[2, 2, 3],\n",
    "                                               time_unit='ms')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T02:59:37.664828Z",
     "start_time": "2024-03-09T02:59:37.513823Z"
    }
   },
   "id": "1e93f7f653727aa0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_ecdf(delays_dataset,\n",
    "              output_names=[\"GPT-3 MoE 8x350M\", \"GPT-3 MoE 32x1.3B\", \"GPT-3 MoE 32x350M\"],\n",
    "              file_prefix='figures/',\n",
    "              addenda=[\"1x8 V100 GPUs\", \"8x4 A100 GPUs\", \"8x4 A100 GPUs\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82adbb2a7f1ede0e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_straggler_delays(delays_dataset,\n",
    "                          output_names=[\"GPT-3 MoE 8x350M\", \"GPT-3 MoE 32x1.3B\", \"GPT-3 MoE 32x350M\"],\n",
    "                          file_prefix='figures/',\n",
    "                          addenda=[\"1x8 V100 GPUs\", \"8x4 A100 GPUs\", \"8x4 A100 GPUs\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a781daad47b34baa",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
